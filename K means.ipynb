{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f57786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\aps\\demo\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in d:\\aps\\demo\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: scikit-learn in d:\\aps\\demo\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib in d:\\aps\\demo\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\aps\\demo\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\aps\\demo\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\aps\\demo\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\aps\\demo\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\aps\\demo\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\aps\\demo\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e0402c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# # K-Means Clustering Implementation\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the encoded data and cleaned data\n",
    "encoded_data = pd.read_csv('D:/Myproject4/encoded_data.csv', index_col=0)\n",
    "cleaned_data = pd.read_csv('D:/Myproject4/cleaned_data.csv', index_col=0)\n",
    "\n",
    "# Align the DataFrames by common indices\n",
    "encoded_data_aligned = encoded_data.loc[encoded_data.index.isin(cleaned_data.index)]\n",
    "cleaned_data_aligned = cleaned_data.loc[cleaned_data.index.isin(encoded_data.index)]\n",
    "\n",
    "# Verify the Alignment if the indices are now aligned\n",
    "print(encoded_data_aligned.index.equals(cleaned_data_aligned.index))\n",
    "\n",
    "# Save the aligned DataFrames\n",
    "#encoded_data_aligned.to_csv('D:/Myproject4/encoded_data_aligned.csv')\n",
    "#cleaned_data_aligned.to_csv('D:/Myproject4/cleaned_data_aligned.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6028f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Index: Index(['AB FOODS POINT', 'Janta Sweet House', 'theka coffee desi', 'Singh Hut',\n",
      "       'GRILL MASTERS', 'Sam Uncle', 'shere punjab veg',\n",
      "       'Shri Balaji Vaishno Dhaba', 'Hinglaj Kachori Bhandhar', 'yummy hub',\n",
      "       ...\n",
      "       'THE  SNACKS HOUSE', 'Sabroso Restaurant', 'Shree Sawji Mutton Bhakar',\n",
      "       'Yummy Momo's Cafe', 'Krishna Warhadi That', 'The Food Delight',\n",
      "       'MAITRI FOODS & BEVERAGES', 'Cafe Bella Ciao', 'GRILL ZILLA',\n",
      "       'Lazeez kitchen'],\n",
      "      dtype='object', name='name', length=148388)\n",
      "                                  city  rating  rating_count   cost  \\\n",
      "name                                                                  \n",
      "Janta Sweet House               Abohar     4.4          50.0  200.0   \n",
      "theka coffee desi               Abohar     3.8         100.0  100.0   \n",
      "Singh Hut                       Abohar     3.7          20.0  250.0   \n",
      "GRILL MASTERS                   Abohar     3.0          10.0  250.0   \n",
      "GRILL MASTERS                  Barnala     3.9          20.0  150.0   \n",
      "GRILL MASTERS      Zirakpur,Chandigarh     3.0          10.0  300.0   \n",
      "GRILL MASTERS                Gurdaspur     3.0          10.0  120.0   \n",
      "GRILL MASTERS                     Jind     4.1          20.0  200.0   \n",
      "Sam Uncle                       Abohar     3.6          20.0  200.0   \n",
      "\n",
      "                                      cuisine  Cluster  \n",
      "name                                                    \n",
      "Janta Sweet House               Sweets,Bakery        2  \n",
      "theka coffee desi                   Beverages        2  \n",
      "Singh Hut                    Fast Food,Indian        2  \n",
      "GRILL MASTERS      Italian-American,Fast Food        2  \n",
      "GRILL MASTERS                         Italian        2  \n",
      "GRILL MASTERS             Fast Food,Beverages        2  \n",
      "GRILL MASTERS             Continental,Italian        2  \n",
      "GRILL MASTERS                  Pizzas,Italian        2  \n",
      "Sam Uncle                         Continental        2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Load the encoded data\n",
    "encoded_data = pd.read_csv(r'D:\\Myproject4\\encoded_data.csv', index_col=0)\n",
    "\n",
    "# Function for K-Means Clustering\n",
    "def kmeans_clustering(encoded_data, n_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    encoded_data['Cluster'] = kmeans.fit_predict(encoded_data)\n",
    "    return encoded_data, kmeans\n",
    "\n",
    "# Perform clustering on encoded data\n",
    "encoded_data_with_clusters, kmeans_model = kmeans_clustering(encoded_data, n_clusters=5)\n",
    "\n",
    "# Load the cleaned data\n",
    "cleaned_data = pd.read_csv('D:/Myproject4/cleaned_data.csv', index_col=0)\n",
    "\n",
    "# Add the cluster information to the cleaned data\n",
    "# Assuming 'encoded_data' corresponds to the same rows as 'cleaned_data'\n",
    "cleaned_data['Cluster'] = encoded_data_with_clusters['Cluster']\n",
    "\n",
    "# Check the index of the cleaned data to confirm how to reference rows\n",
    "print(\"Cleaned Data Index:\", cleaned_data.index)\n",
    "\n",
    "# Get the cluster of a specific restaurant by integer position # restaurant_position = 0  # Change this to the desired restaurant position\n",
    "restaurant_position = 0  # You can change this to the position of the restaurant \n",
    "\n",
    "# Use .iloc to access rows by integer position (ignores index)\n",
    "restaurant_cluster = cleaned_data.iloc[restaurant_position]['Cluster']\n",
    "\n",
    "# Get restaurants from the same cluster (excluding the restaurant itself)\n",
    "similar_restaurants = cleaned_data[cleaned_data['Cluster'] == restaurant_cluster].index.tolist()\n",
    "similar_restaurants.remove(cleaned_data.index[restaurant_position])  # Remove the restaurant itself from the recommendations\n",
    "\n",
    "# Get the top 5 recommended restaurants (if there are enough in the same cluster)\n",
    "top_5_recommendations = cleaned_data.loc[similar_restaurants[:5]]\n",
    "\n",
    "# Display the recommended restaurants\n",
    "print(top_5_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e5f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
